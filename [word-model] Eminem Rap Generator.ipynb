{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.utils.data_utils import get_file\n",
    "from random import randint\n",
    "from collections import OrderedDict \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import sys\n",
    "import io\n",
    "import re\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs = pd.read_csv('data/cardi-b-lyrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokenized_lines(df):\n",
    "    words = []\n",
    "    \n",
    "    for index, row in df['lyrics'].iteritems():\n",
    "        row = str(row).lower()\n",
    "        for line in row.split('|-|'):\n",
    "            new_words = re.findall(r\"\\b[a-z']+\\b\", unidecode(line))\n",
    "            words = words + new_words\n",
    "        \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lyric_lines = get_tokenized_lines(songs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sequences: 19353\n"
     ]
    }
   ],
   "source": [
    "SEQ_LENGTH = 50 + 1\n",
    "sequences = list()\n",
    "\n",
    "for i in range(SEQ_LENGTH, len(all_lyric_lines)):\n",
    "    seq = all_lyric_lines[i - SEQ_LENGTH: i]\n",
    "    sequences.append(seq)\n",
    "\n",
    "print('Total Sequences: %d' % len(sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_doc(lines, filename):\n",
    "    for line in lines:\n",
    "        data = ' '.join(line)\n",
    "        \n",
    "    '\\n'.join(data)\n",
    "    file = open(filename, 'w')\n",
    "    file.write(data)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_filename = 'sequences.txt'\n",
    "save_doc(sequences, out_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"'s\": 0, 'a': 1, 'aarp': 2, 'abort': 3, 'about': 4, 'above': 5, 'abraza': 6, 'abrupt': 7, 'account': 8, 'accounts': 9, 'ace': 10, 'acento': 11, 'across': 12, 'act': 13, 'actin': 14, 'acting': 15, 'activos': 16, 'actually': 17, 'addicted': 18, 'administer': 19, 'admiring': 20, 'adore': 21, 'afford': 22, \"afisia'o\": 23, 'afisiado': 24, 'after': 25, 'again': 26, 'ago': 27, 'ah': 28, 'aha': 29, 'ahora': 30, \"ain't\": 31, 'air': 32, 'airplane': 33, 'alante': 34, 'album': 35, 'albums': 36, 'algo': 37, 'alive': 38, 'all': 39, 'alla': 40, 'allow': 41, 'alone': 42, 'alright': 43, 'always': 44, 'am': 45, 'amar': 46, 'amends': 47, 'amigas': 48, 'ammunition': 49, 'amor': 50, 'an': 51, 'and': 52, 'andamo': 53, 'andamos': 54, 'ando': 55, 'andre': 56, 'andretti': 57, 'angel': 58, 'anger': 59, 'ano': 60, 'another': 61, 'answer': 62, 'any': 63, 'anybody': 64, 'anymore': 65, \"apaga'o\": 66, 'aparte': 67, 'apartments': 68, 'appetit': 69, 'aqui': 70, 'ar': 71, 'are': 72, \"aren't\": 73, 'armadillo': 74, 'arms': 75, 'around': 76, 'arranca': 77, 'arregle': 78, 'as': 79, 'ash': 80, 'ashamed': 81, 'asi': 82, 'ask': 83, 'ass': 84, 'asscheeks': 85, 'asses': 86, 'assume': 87, 'aston': 88, 'at': 89, 'atras': 90, 'attention': 91, 'attitude': 92, 'audience': 93, 'aunque': 94, 'average': 95, 'averiguar': 96, 'award': 97, 'away': 98, 'ay': 99, 'aye': 100, 'ayesha': 101, 'ayy': 102, 'azuca': 103, 'azucar': 104, 'b': 105, 'babe': 106, 'baby': 107, 'babys': 108, 'bachata': 109, 'back': 110, 'background': 111, 'backhand': 112, 'backlash': 113, 'backstreets': 114, 'bad': 115, 'badder': 116, 'badges': 117, 'bae': 118, 'bag': 119, 'baggage': 120, 'bags': 121, 'bah': 122, 'baila': 123, 'bailame': 124, 'bajo': 125, 'bake': 126, 'balenciaga': 127, 'balenciagas': 128, 'ball': 129, 'ballin': 130, 'balls': 131, 'banco': 132, 'bands': 133, 'bang': 134, 'bangers': 135, 'bangin': 136, 'banging': 137, 'bank': 138, 'banks': 139, 'bape': 140, 'bar': 141, 'bardi': 142, 'bare': 143, 'barely': 144, 'basic': 145, 'basura': 146, 'bat': 147, 'bathroom': 148, 'be': 149, 'beast': 150, 'beat': 151, 'beater': 152, 'beating': 153, 'bebe': 154, 'because': 155, 'bed': 156, 'beef': 157, 'beefin': 158, 'been': 159, 'before': 160, 'beggin': 161, 'behalf': 162, 'behind': 163, 'being': 164, 'belichick': 165, 'believe': 166, 'belly': 167, 'belt': 168, 'bend': 169, 'benjamin': 170, 'bentley': 171, 'besame': 172, 'beso': 173, 'best': 174, 'bet': 175, 'better': 176, 'between': 177, 'beyonce': 178, 'bi': 179, 'bible': 180, 'big': 181, 'biggest': 182, 'bike': 183, 'bilingual': 184, 'bill': 185, 'billboard': 186, 'billetes': 187, 'bills': 188, 'binderella': 189, 'birkin': 190, 'birthday': 191, 'bitch': 192, 'bitches': 193, 'black': 194, 'blah': 195, 'blame': 196, 'blap': 197, 'blat': 198, 'bleach': 199, 'bleeding': 200, 'bleezy': 201, 'blessings': 202, 'bling': 203, 'block': 204, 'blocks': 205, 'blood': 206, 'bloody': 207, 'blow': 208, 'blowin': 209, 'blowing': 210, 'blue': 211, 'blunt': 212, 'bmx': 213, 'boardin': 214, 'boat': 215, 'bobby': 216, 'bobo': 217, 'boca': 218, 'bodegas': 219, 'body': 220, 'bon': 221, 'bone': 222, 'bones': 223, 'boo': 224, 'boobs': 225, 'boogie': 226, 'boom': 227, 'boosie': 228, 'booty': 229, 'bopper': 230, 'boricuas': 231, 'born': 232, 'boss': 233, 'bossed': 234, 'botellas': 235, 'both': 236, 'bother': 237, 'bottom': 238, 'bottoms': 239, 'bought': 240, 'boujee': 241, 'boulder': 242, 'boulders': 243, 'bout': 244, 'bow': 245, 'bowl': 246, 'box': 247, 'boy': 248, 'boys': 249, 'bracelet': 250, 'brag': 251, 'braids': 252, 'brain': 253, 'brains': 254, 'brand': 255, 'bras': 256, 'brass': 257, 'bread': 258, 'break': 259, 'bricks': 260, 'bridge': 261, 'brillo': 262, 'bring': 263, 'britain': 264, 'britney': 265, 'bro': 266, 'broad': 267, 'broke': 268, 'bron': 269, 'bronx': 270, 'bronze': 271, 'bros': 272, 'brother': 273, 'brr': 274, 'brrr': 275, 'brrrp': 276, 'brrrt': 277, 'brrt': 278, 'bruisin': 279, 'bruno': 280, 'bu': 281, 'bubble': 282, 'bugatti': 283, 'built': 284, 'bulla': 285, 'bullet': 286, 'bulletproof': 287, 'bully': 288, 'bum': 289, 'bun': 290, 'bunny': 291, 'buried': 292, 'burke': 293, 'busca': 294, 'business': 295, 'bust': 296, 'bustin': 297, 'busting': 298, 'but': 299, 'butter': 300, 'buy': 301, 'by': 302, 'c': 303, 'cabron': 304, \"caesar's\": 305, 'cage': 306, 'caiga': 307, 'cake': 308, 'caked': 309, 'cakes': 310, 'call': 311, 'callate': 312, 'calle': 313, 'calls': 314, 'came': 315, 'can': 316, \"can't\": 317, 'cancion': 318, 'candy': 319, 'cannot': 320, 'cansa': 321, 'cappin': 322, 'car': 323, 'cara': 324, 'carajo': 325, 'cardi': 326, \"cardi's\": 327, 'cardio': 328, 'care': 329, 'cared': 330, 'career': 331, 'careful': 332, 'carefully': 333, 'carpets': 334, 'carriage': 335, 'cars': 336, 'cartera': 337, 'carti': 338, 'cartier': 339, 'cartwheels': 340, 'casa': 341, 'case': 342, 'cash': 343, 'cass': 344, 'cat': 345, 'catch': 346, 'catchin': 347, 'catfishin': 348, 'caught': 349, 'cause': 350, 'ceiling': 351, 'celebrate': 352, 'celia': 353, 'cereal': 354, 'certain': 355, 'certified': 356, 'ch': 357, 'chain': 358, 'chains': 359, 'challenge': 360, 'chambean': 361, 'champ': 362, 'champagne': 363, 'championa': 364, 'chan': 365, 'chance': 366, 'chandelier': 367, 'chanel': 368, 'chanels': 369, 'change': 370, 'changed': 371, 'chapeando': 372, 'charges': 373, 'charms': 374, 'charts': 375, 'charytin': 376, 'chasin': 377, 'cheap': 378, 'cheat': 379, 'check': 380, 'checked': 381, 'checks': 382, 'cheese': 383, 'chef': 384, 'chest': 385, 'chevy': 386, 'chew': 387, 'chick': 388, 'chicken': 389, 'child': 390, 'chill': 391, 'chillin': 392, 'chilling': 393, 'chills': 394, 'ching': 395, 'chingan': 396, 'chips': 397, 'chokin': 398, 'choose': 399, 'choppa': 400, 'chopped': 401, 'chopper': 402, 'choppin': 403, 'chops': 404, 'chosen': 405, 'chrissy': 406, 'church': 407, 'cien': 408, 'cigarettes': 409, 'cincuenta': 410, 'city': 411, 'civilians': 412, 'clack': 413, 'claimin': 414, 'claritin': 415, 'clear': 416, 'click': 417, 'climbed': 418, 'clip': 419, 'clique': 420, 'close': 421, 'closed': 422, 'closet': 423, 'club': 424, 'clue': 425, 'coat': 426, 'cobrando': 427, 'coffee': 428, 'coins': 429, 'coja': 430, 'cold': 431, 'collard': 432, 'colombianas': 433, 'come': 434, 'comes': 435, 'comfortable': 436, 'comin': 437, 'coming': 438, 'commas': 439, 'commentary': 440, 'comments': 441, 'commitment': 442, 'como': 443, 'comoda': 444, 'competin': 445, 'competition': 446, 'compliment': 447, 'compra': 448, 'comprar': 449, 'compras': 450, 'compro': 451, 'con': 452, 'concentrate': 453, 'concrete': 454, 'condoms': 455, 'confidence': 456, 'confused': 457, 'conmigo': 458, \"connection's\": 459, 'conocen': 460, 'contact': 461, 'contigo': 462, 'contour': 463, 'contra': 464, 'cookin': 465, 'cool': 466, 'coolant': 467, 'coordinates': 468, 'cop': 469, 'copian': 470, 'copyin': 471, 'cora': 472, 'corito': 473, 'cork': 474, 'cornbread': 475, 'corny': 476, 'coro': 477, 'cosa': 478, 'cosas': 479, 'cost': 480, 'costco': 481, 'cotton': 482, 'could': 483, \"could've\": 484, \"couldn't\": 485, 'count': 486, 'coupe': 487, 'couple': 488, 'course': 489, 'court': 490, 'cover': 491, 'covered': 492, 'crack': 493, 'crash': 494, 'crazy': 495, 'creeme': 496, 'creep': 497, 'creeping': 498, 'crees': 499, 'crew': 500, 'crib': 501, 'crippin': 502, 'criss': 503, 'crown': 504, 'cruz': 505, 'cuando': 506, 'cubanas': 507, 'cuero': 508, 'cueros': 509, 'cuerpo': 510, 'cuffed': 511, 'culo': 512, 'cum': 513, 'cums': 514, 'cup': 515, 'curi': 516, \"curry's\": 517, 'curtains': 518, 'custom': 519, 'cut': 520, 'd': 521, \"d'usse\": 522, 'da': 523, 'daddy': 524, 'dame': 525, 'damn': 526, 'dance': 527, 'dancing': 528, 'danger': 529, 'daniel': 530, 'dante': 531, 'dapper': 532, 'dark': 533, 'darle': 534, 'dasani': 535, 'dash': 536, 'dat': 537, 'daughter': 538, 'day': 539, 'daylight': 540, 'days': 541, 'daytrip': 542, 'de': 543, 'dead': 544, 'deal': 545, 'dealing': 546, 'deals': 547, 'decide': 548, 'defined': 549, 'dejarme': 550, 'dejo': 551, 'demonstrate': 552, 'demora': 553, 'dentro': 554, 'dependo': 555, 'deposit': 556, 'depositando': 557, 'desespero': 558, 'designer': 559, 'despues': 560, 'devil': 561, 'di': 562, 'diablo': 563, 'dial': 564, 'diamond': 565, 'diamonds': 566, 'diaper': 567, 'dicen': 568, 'dick': 569, 'did': 570, \"didn't\": 571, 'die': 572, 'dientes': 573, 'dieta': 574, 'different': 575, 'diles': 576, 'dinero': 577, 'ding': 578, 'dinner': 579, 'dior': 580, 'dip': 581, 'dipper': 582, 'dique': 583, 'dirt': 584, 'dirty': 585, 'disappear': 586, 'disco': 587, 'dispose': 588, 'disque': 589, 'disrespect': 590, 'diss': 591, 'dissed': 592, 'dissin': 593, 'district': 594, 'diva': 595, 'dj': 596, 'do': 597, 'dog': 598, 'doin': 599, 'doing': 600, 'dollar': 601, 'dollars': 602, 'dominicana': 603, \"don't\": 604, 'donde': 605, 'done': 606, 'dong': 607, 'donuts': 608, 'dooney': 609, 'doors': 610, 'dope': 611, 'dork': 612, 'dos': 613, 'doscientos': 614, 'dots': 615, 'double': 616, 'dough': 617, 'down': 618, 'draco': 619, 'drawers': 620, 'dreams': 621, 'dress': 622, 'dressed': 623, 'drink': 624, 'drip': 625, 'drippin': 626, 'dripping': 627, 'drive': 628, 'driven': 629, 'driver': 630, 'driveway': 631, 'driving': 632, 'drop': 633, 'dropped': 634, 'droppin': 635, 'dropping': 636, 'drown': 637, 'drunk': 638, 'dud': 639, 'dude': 640, 'dumb': 641, 'dura': 642, 'during': 643, 'dyin': 644, 'e': 645, 'ear': 646, 'ears': 647, 'easy': 648, 'eat': 649, 'eatin': 650, 'eating': 651, 'eazy': 652, 'eddie': 653, 'eeoow': 654, 'egg': 655, 'eh': 656, 'either': 657, 'el': 658, 'elevators': 659, 'ella': 660, 'ellos': 661, 'else': 662, 'em': 663, 'embala': 664, 'emergency': 665, 'emisora': 666, 'en': 667, 'enamorarte': 668, 'end': 669, 'enough': 670, 'entero': 671, 'entrada': 672, 'entree': 673, 'envy': 674, 'eres': 675, 'es': 676, 'esa': 677, 'escucha': 678, 'escuchado': 679, 'eso': 680, 'espalda': 681, 'esposo': 682, 'esta': 683, 'estaba': 684, 'estar': 685, 'estas': 686, 'even': 687, 'ever': 688, 'every': 689, 'everybody': 690, 'everyone': 691, 'everythin': 692, 'everything': 693, 'everywhere': 694, 'ex': 695, 'except': 696, 'exes': 697, 'exhausted': 698, 'expect': 699, 'expensive': 700, 'ey': 701, 'eye': 702, 'eyes': 703, 'face': 704, 'faced': 705, 'fact': 706, 'facts': 707, 'fade': 708, 'fair': 709, 'fairy': 710, 'fake': 711, 'fam': 712, 'fame': 713, 'fans': 714, 'fashion': 715, 'fast': 716, 'fastin': 717, 'fat': 718, 'father': 719, 'favorite': 720, 'fear': 721, 'fears': 722, 'fed': 723, 'fee': 724, 'feel': 725, 'feelin': 726, 'feeling': 727, 'feelings': 728, 'feels': 729, 'fellas': 730, 'felony': 731, 'felt': 732, 'fendi': 733, 'ferrari': 734, 'few': 735, 'field': 736, 'fifty': 737, 'fight': 738, 'fighting': 739, 'figure': 740, 'figured': 741, 'figures': 742, 'fill': 743, 'filling': 744, 'filthy': 745, 'find': 746, 'fine': 747, 'finesse': 748, 'fineto': 749, 'finger': 750, 'fingers': 751, 'finish': 752, 'finished': 753, 'finna': 754, 'fire': 755, 'firing': 756, 'first': 757, 'fit': 758, 'fitting': 759, 'fixed': 760, 'flag': 761, 'flakes': 762, 'flames': 763, 'flattering': 764, 'flavor': 765, 'flawed': 766, 'fleek': 767, 'flesh': 768, 'flex': 769, 'flexin': 770, 'flexing': 771, 'flight': 772, 'flip': 773, 'flirt': 774, 'float': 775, 'floatin': 776, 'flooded': 777, 'floor': 778, 'florida': 779, 'flow': 780, 'fly': 781, 'foam': 782, 'foe': 783, \"follie's\": 784, 'follow': 785, 'food': 786, 'footies': 787, 'for': 788, 'forbidden': 789, 'fore': 790, 'foreign': 791, 'forever': 792, 'forfeit': 793, 'forget': 794, 'forgive': 795, 'forgot': 796, 'forma': 797, 'fortune': 798, 'foul': 799, 'foxx': 800, 'fragancia': 801, 'fragile': 802, 'fragrance': 803, 'frames': 804, 'franco': 805, 'fraud': 806, 'freak': 807, 'free': 808, 'freezed': 809, 'freezer': 810, 'french': 811, 'friday': 812, 'friend': 813, 'friends': 814, \"friends'll\": 815, 'from': 816, 'front': 817, 'fronts': 818, 'frosted': 819, 'fruit': 820, 'fuck': 821, 'fucked': 822, 'fuckin': 823, 'fucking': 824, 'fue': 825, 'fugazy': 826, 'full': 827, 'fumando': 828, 'fun': 829, 'funds': 830, 'fur': 831, 'further': 832, 'g': 833, \"g's\": 834, \"ga'to\": 835, 'gadgets': 836, 'gaga': 837, 'gain': 838, 'game': 839, 'gang': 840, 'gangsta': 841, 'gas': 842, 'gasolina': 843, 'gasta': 844, 'gate': 845, 'gave': 846, 'gears': 847, 'gente': 848, 'georgia': 849, 'gerald': 850, 'get': 851, 'gettin': 852, 'getting': 853, 'ghost': 854, 'gift': 855, 'gigglin': 856, 'gimme': 857, 'girl': 858, 'girls': 859, 'give': 860, 'given': 861, 'givenchy': 862, 'giving': 863, 'glad': 864, 'glistenin': 865, 'glitter': 866, 'globe': 867, 'glock': 868, 'glory': 869, 'go': 870, 'goals': 871, 'god': 872, 'goddamn': 873, 'goes': 874, 'goin': 875, 'going': 876, 'gold': 877, 'gon': 878, 'gonna': 879, 'good': 880, 'gooshy': 881, 'got': 882, 'gotta': 883, 'gotti': 884, 'goza': 885, 'grab': 886, 'gram': 887, 'grandma': 888, 'grasa': 889, 'gratis': 890, 'grave': 891, 'great': 892, 'greek': 893, 'green': 894, 'greens': 895, 'griffen': 896, 'grills': 897, 'grim': 898, 'grind': 899, 'group': 900, 'groupie': 901, 'grrr': 902, 'guac': 903, 'guap': 904, 'gucci': 905, 'guerrero': 906, 'guess': 907, 'guets': 908, 'guitar': 909, 'gun': 910, 'gunshot': 911, 'gusta': 912, 'gustan': 913, 'guts': 914, 'guys': 915, 'ha': 916, 'hablan': 917, 'hablas': 918, 'hables': 919, 'hacer': 920, 'hacerte': 921, 'haces': 922, 'haciendo': 923, 'had': 924, 'hagas': 925, 'hago': 926, 'hah': 927, 'hahahahaaa': 928, 'hair': 929, 'halal': 930, 'half': 931, 'hammer': 932, 'hand': 933, 'hands': 934, 'handsome': 935, 'hang': 936, 'hangers': 937, 'happen': 938, 'harass': 939, 'hard': 940, 'harley': 941, 'has': 942, 'hashtag': 943, 'hasta': 944, 'hate': 945, 'hated': 946, 'hater': 947, 'hatin': 948, 'hating': 949, 'have': 950, \"haven't\": 951, 'havin': 952, 'having': 953, 'haze': 954, 'he': 955, \"he's\": 956, 'head': 957, 'headline': 958, 'heads': 959, 'headshot': 960, 'hear': 961, 'heard': 962, 'hearse': 963, 'heart': 964, 'heartless': 965, 'heat': 966, 'heels': 967, 'heh': 968, 'hehehehe': 969, 'hell': 970, 'hella': 971, 'her': 972, 'here': 973, \"here's\": 974, 'hermano': 975, 'hers': 976, 'hey': 977, 'hide': 978, 'high': 979, 'higher': 980, 'hijas': 981, 'hill': 982, 'hills': 983, 'him': 984, 'hip': 985, 'his': 986, 'hit': 987, 'hits': 988, 'ho': 989, 'hoe': 990, 'hoes': 991, 'hol': 992, 'hold': 993, 'holdin': 994, 'holla': 995, 'home': 996, 'homie': 997, 'honestly': 998, 'honey': 999, 'hood': 1000, 'hoodie': 1001, 'hooka': 1002, 'hookah': 1003, 'hooked': 1004, 'hop': 1005, 'hope': 1006, 'hoppin': 1007, 'horchata': 1008, 'horse': 1009, 'hot': 1010, 'hotboxin': 1011, 'hotter': 1012, 'hottest': 1013, 'hours': 1014, 'house': 1015, 'hov': 1016, 'how': 1017, 'hubo': 1018, 'huh': 1019, 'human': 1020, 'humble': 1021, 'huncho': 1022, 'hundred': 1023, 'hunnit': 1024, 'hunter': 1025, 'hurrr': 1026, 'hurt': 1027, 'hurtin': 1028, 'hype': 1029, 'i': 1030, \"i'll\": 1031, \"i'm\": 1032, \"i'ma\": 1033, \"i've\": 1034, 'iba': 1035, 'ice': 1036, 'if': 1037, 'immortal': 1038, 'impeccable': 1039, 'importa': 1040, 'imported': 1041, 'in': 1042, 'inches': 1043, 'inconsistent': 1044, 'independent': 1045, 'indictments': 1046, 'insane': 1047, 'inside': 1048, 'instead': 1049, 'interior': 1050, 'into': 1051, 'introduce': 1052, 'invasion': 1053, 'invest': 1054, 'invite': 1055, 'iron': 1056, 'is': 1057, 'it': 1058, \"it's\": 1059, 'itchin': 1060, 'its': 1061, 'iyanla': 1062, 'j': 1063, \"j's\": 1064, 'jacket': 1065, 'jackie': 1066, 'jag': 1067, 'jail': 1068, 'jalan': 1069, 'jambalaya': 1070, 'james': 1071, 'jamie': 1072, 'jared': 1073, 'jeans': 1074, 'jeepeta': 1075, 'jejeje': 1076, 'jelly': 1077, 'jenny': 1078, 'jerry': 1079, 'jesucristo': 1080, 'jesus': 1081, 'jet': 1082, 'jets': 1083, 'jeva': 1084, 'jevo': 1085, 'jew': 1086, 'jeweler': 1087, 'jewels': 1088, 'jimmy': 1089, 'jit': 1090, 'job': 1091, 'jodeci': 1092, 'jogging': 1093, 'jon': 1094, 'jordan': 1095, 'joy': 1096, 'juan': 1097, 'juca': 1098, 'juice': 1099, 'juicy': 1100, 'jump': 1101, 'jumpin': 1102, 'junk': 1103, 'just': 1104, 'k': 1105, 'kamaiyah': 1106, 'karats': 1107, 'karma': 1108, 'keep': 1109, 'keepin': 1110, 'keisha': 1111, 'keith': 1112, 'kemba': 1113, 'ken': 1114, 'keyed': 1115, 'keys': 1116, 'kick': 1117, 'kill': 1118, 'killer': 1119, 'killin': 1120, 'killing': 1121, 'kilo': 1122, 'kinda': 1123, 'king': 1124, 'kiss': 1125, 'kissin': 1126, 'kitten': 1127, 'kitty': 1128, 'knack': 1129, 'knee': 1130, 'knew': 1131, 'knick': 1132, 'knock': 1133, 'knot': 1134, 'know': 1135, 'knowles': 1136, 'knows': 1137, 'knuckles': 1138, 'kulture': 1139, 'kush': 1140, 'la': 1141, 'label': 1142, 'labels': 1143, 'lace': 1144, 'laced': 1145, 'ladies': 1146, 'lady': 1147, \"lady's\": 1148, 'laid': 1149, 'lake': 1150, 'lam': 1151, 'lambo': 1152, 'lamborghin': 1153, 'lamborghini': 1154, 'lame': 1155, 'lamp': 1156, 'land': 1157, 'lane': 1158, 'lanes': 1159, 'laps': 1160, 'lara': 1161, 'large': 1162, 'las': 1163, 'last': 1164, 'lasted': 1165, 'late': 1166, 'later': 1167, 'latino': 1168, 'laugh': 1169, 'laurent': 1170, 'lawyer': 1171, 'lay': 1172, 'layover': 1173, 'le': 1174, 'lead': 1175, 'leaf': 1176, 'league': 1177, 'lear': 1178, 'learn': 1179, 'learned': 1180, 'least': 1181, 'leather': 1182, 'leave': 1183, 'left': 1184, 'legos': 1185, 'legs': 1186, 'les': 1187, 'less': 1188, 'lesson': 1189, 'lessons': 1190, 'let': 1191, \"let's\": 1192, 'levitate': 1193, 'lick': 1194, 'lie': 1195, 'life': 1196, 'light': 1197, 'lights': 1198, 'like': 1199, 'likes': 1200, 'liking': 1201, 'lil': 1202, 'limit': 1203, 'line': 1204, 'lined': 1205, 'lines': 1206, 'linked': 1207, 'lion': 1208, 'lips': 1209, 'lipstick': 1210, 'liquid': 1211, 'listenin': 1212, 'lit': 1213, 'little': 1214, 'live': 1215, 'lives': 1216, 'livin': 1217, 'living': 1218, 'llama': 1219, 'llegando': 1220, 'llego': 1221, 'llevo': 1222, 'lo': 1223, 'lock': 1224, 'locked': 1225, 'lollipoppin': 1226, 'lombardi': 1227, 'long': 1228, 'look': 1229, 'lookie': 1230, 'lookin': 1231, 'looking': 1232, 'looks': 1233, 'loose': 1234, 'loquita': 1235, 'lord': 1236, 'los': 1237, 'lose': 1238, 'losin': 1239, 'lost': 1240, 'lot': 1241, 'louboutin': 1242, 'louis': 1243, 'love': 1244, \"love's\": 1245, 'loves': 1246, 'lovin': 1247, 'loving': 1248, 'low': 1249, 'lower': 1250, 'ls': 1251, 'lucas': 1252, 'lucy': 1253, 'luxury': 1254, 'lying': 1255, 'm': 1256, 'ma': 1257, 'mac': 1258, 'mad': 1259, 'made': 1260, 'madre': 1261, 'magazines': 1262, 'magic': 1263, 'magnetic': 1264, 'mail': 1265, 'main': 1266, 'makaveli': 1267, 'make': 1268, 'makeover': 1269, 'makeup': 1270, 'makin': 1271, 'making': 1272, 'mal': 1273, 'maletin': 1274, 'mall': 1275, 'mama': 1276, 'mami': 1277, 'man': 1278, 'mansion': 1279, 'many': 1280, 'marble': 1281, 'margarine': 1282, 'mario': 1283, 'married': 1284, 'martian': 1285, 'marty': 1286, 'mas': 1287, 'mask': 1288, 'match': 1289, 'matter': 1290, 'maybach': 1291, 'maybe': 1292, 'mayor': 1293, \"mcdonald's\": 1294, 'me': 1295, 'meals': 1296, 'mean': 1297, 'means': 1298, 'measurements': 1299, 'medical': 1300, 'meet': 1301, 'mejor': 1302, 'melt': 1303, 'member': 1304, 'menciona': 1305, 'mente': 1306, 'mention': 1307, 'meow': 1308, 'merenge': 1309, 'meses': 1310, 'mess': 1311, 'message': 1312, 'messages': 1313, 'messiah': 1314, 'met': 1315, 'mete': 1316, 'mi': 1317, 'mia': 1318, 'mic': 1319, 'michael': 1320, 'middle': 1321, 'mierda': 1322, 'might': 1323, 'mike': 1324, 'mill': 1325, 'mille': 1326, 'milli': 1327, 'million': 1328, 'millions': 1329, 'mills': 1330, 'mind': 1331, 'minded': 1332, 'mine': 1333, 'mingle': 1334, 'mink': 1335, 'minute': 1336, 'minutes': 1337, 'mio': 1338, 'mira': 1339, 'mirror': 1340, 'mis': 1341, 'misfortunate': 1342, 'miss': 1343, 'missed': 1344, 'mission': 1345, 'mixed': 1346, 'mixtapes': 1347, 'mode': 1348, 'modelame': 1349, 'models': 1350, 'moe': 1351, 'molly': 1352, 'mom': 1353, 'momma': 1354, 'mommy': 1355, 'mona': 1356, 'monday': 1357, 'money': 1358, 'monsta': 1359, \"monsta's\": 1360, 'months': 1361, 'mood': 1362, 'moonrocks': 1363, 'moonwalk': 1364, 'moonwalkin': 1365, 'mora': 1366, 'more': 1367, 'mornin': 1368, 'most': 1369, 'mothafucker': 1370, 'mothafuckin': 1371, 'motherfuckers': 1372, 'motherfuckin': 1373, 'motin': 1374, 'motorsport': 1375, 'motorville': 1376, 'mouth': 1377, 'move': 1378, 'moves': 1379, 'movie': 1380, 'ms': 1381, 'much': 1382, 'mucha': 1383, 'mud': 1384, 'mudarla': 1385, 'mude': 1386, 'mueve': 1387, 'mundo': 1388, 'murda': 1389, 'murder': 1390, 'must': 1391, 'mustard': 1392, 'mwah': 1393, 'my': 1394, 'myers': 1395, 'myself': 1396, 'na': 1397, 'nadie': 1398, 'nah': 1399, 'nails': 1400, 'naked': 1401, 'name': 1402, 'named': 1403, 'nasty': 1404, 'nawf': 1405, 'near': 1406, 'necesito': 1407, 'neck': 1408, 'need': 1409, 'needs': 1410, 'nervous': 1411, 'never': 1412, 'new': 1413, 'news': 1414, 'next': 1415, 'ni': 1416, 'nice': 1417, 'nick': 1418, 'nicki': 1419, 'nigga': 1420, 'niggas': 1421, 'night': 1422, 'nightclub': 1423, 'nights': 1424, 'nike': 1425, 'nine': 1426, 'ninety': 1427, 'ninguno': 1428, 'no': 1429, 'noche': 1430, 'nombre': 1431, 'non': 1432, 'none': 1433, 'nope': 1434, 'nos': 1435, 'nose': 1436, 'nosebleeds': 1437, 'not': 1438, 'nothin': 1439, 'nothing': 1440, 'nova': 1441, 'noventa': 1442, 'novio': 1443, 'now': 1444, 'nowhere': 1445, 'nudes': 1446, 'nuggets': 1447, 'number': 1448, 'numbers': 1449, 'nuts': 1450, 'o': 1451, 'of': 1452, 'off': 1453, 'office': 1454, 'offset': 1455, 'oh': 1456, 'okay': 1457, 'okurrrt': 1458, 'old': 1459, 'olvidar': 1460, 'on': 1461, 'once': 1462, 'one': 1463, 'ones': 1464, 'only': 1465, 'ooh': 1466, 'open': 1467, 'opera': 1468, 'opp': 1469, 'options': 1470, 'or': 1471, 'ordered': 1472, 'osea': 1473, 'other': 1474, 'our': 1475, 'out': 1476, 'outta': 1477, 'ovaries': 1478, 'over': 1479, 'overnight': 1480, 'ow': 1481, 'own': 1482, 'oww': 1483, 'oxygen': 1484, 'p': 1485, \"p's\": 1486, 'pa': 1487, \"pa'l\": 1488, 'pack': 1489, 'package': 1490, 'paddywhack': 1491, 'paga': 1492, 'pago': 1493, 'pai': 1494, 'paid': 1495, 'pain': 1496, 'pajamas': 1497, 'panties': 1498, 'paper': 1499, 'parar': 1500, 'park': 1501, 'party': 1502, \"pasadena's\": 1503, 'pasar': 1504, 'paso': 1505, 'passes': 1506, 'past': 1507, 'patek': 1508, 'patty': 1509, 'pay': 1510, 'payola': 1511, 'peacefully': 1512, 'peak': 1513, 'pecho': 1514, 'pedigree': 1515, \"pega'o\": 1516, 'pelear': 1517, 'peligrosa': 1518, 'peluca': 1519, 'pen': 1520, 'pensaba': 1521, 'pensar': 1522, 'people': 1523, 'pep': 1524, 'perc': 1525, 'perfect': 1526, 'perico': 1527, 'period': 1528, 'perky': 1529, 'pero': 1530, 'person': 1531, 'pesos': 1532, 'petroleum': 1533, 'pew': 1534, 'phone': 1535, 'pico': 1536, 'picor': 1537, 'pics': 1538, 'pictures': 1539, 'pido': 1540, 'piece': 1541, 'piguets': 1542, 'piling': 1543, 'pimp': 1544, 'pin': 1545, 'pinatas': 1546, 'pinga': 1547, 'pink': 1548, 'pinky': 1549, 'pipe': 1550, 'pissed': 1551, 'pissy': 1552, 'pistola': 1553, 'pitch': 1554, 'pizza': 1555, 'place': 1556, 'plain': 1557, 'plane': 1558, 'plans': 1559, 'platinums': 1560, 'play': 1561, 'playoffs': 1562, 'plaza': 1563, 'please': 1564, 'plot': 1565, 'pm': 1566, 'podium': 1567, 'pole': 1568, 'police': 1569, 'pompeii': 1570, 'pone': 1571, 'pongo': 1572, 'poolside': 1573, 'pop': 1574, 'popped': 1575, 'poppin': 1576, 'pops': 1577, 'porn': 1578, 'porque': 1579, 'porsche': 1580, 'porsches': 1581, 'posture': 1582, 'pot': 1583, 'potato': 1584, 'potpourri': 1585, 'potty': 1586, 'pound': 1587, 'poured': 1588, 'prada': 1589, 'pray': 1590, 'prayed': 1591, 'preacher': 1592, 'prerogative': 1593, 'press': 1594, 'pressed': 1595, 'pressure': 1596, 'pretty': 1597, 'prey': 1598, 'price': 1599, 'pride': 1600, 'primo': 1601, 'princesa': 1602, 'privacy': 1603, 'private': 1604, 'probar': 1605, 'problem': 1606, 'problematic': 1607, 'product': 1608, 'prohibido': 1609, 'prolly': 1610, 'prom': 1611, 'prove': 1612, 'proving': 1613, 'provocative': 1614, 'pucker': 1615, 'puede': 1616, 'puedes': 1617, 'puerto': 1618, 'pues': 1619, 'pull': 1620, 'pulled': 1621, 'pullin': 1622, 'pulling': 1623, 'pump': 1624, 'punk': 1625, 'purple': 1626, 'pussy': 1627, 'put': 1628, 'putas': 1629, 'qb': 1630, 'quarter': 1631, 'quavo': 1632, 'que': 1633, 'querer': 1634, 'queso': 1635, 'questions': 1636, 'quick': 1637, 'quien': 1638, 'quiera': 1639, 'quieras': 1640, 'quiero': 1641, 'quit': 1642, 'race': 1643, 'racks': 1644, 'raf': 1645, 'rag': 1646, 'raised': 1647, 'random': 1648, 'range': 1649, \"rap's\": 1650, 'rapa': 1651, 'rapera': 1652, 'rapper': 1653, 'rari': 1654, 'rat': 1655, 'ratchet': 1656, 'rather': 1657, 'raw': 1658, 'raza': 1659, 'razzi': 1660, 'reach': 1661, 'reachin': 1662, 'read': 1663, 'ready': 1664, 'real': 1665, 'really': 1666, 'reaper': 1667, 'rear': 1668, 'rears': 1669, 'reason': 1670, 'reciben': 1671, 'record': 1672, 'records': 1673, 'red': 1674, 'refilles': 1675, 'regalan': 1676, 'regardless': 1677, 'relate': 1678, 'relay': 1679, 'reliable': 1680, 'religion': 1681, 'remind': 1682, 'renta': 1683, 'repeat': 1684, 'replied': 1685, 'resentment': 1686, 'reservations': 1687, 'rest': 1688, 'retarded': 1689, 'retirement': 1690, 'retumbe': 1691, 'returnin': 1692, 'rev': 1693, 'rib': 1694, 'rich': 1695, 'richard': 1696, 'richer': 1697, 'riches': 1698, 'ricky': 1699, 'rico': 1700, 'ride': 1701, 'ridin': 1702, 'right': 1703, 'rih': 1704, 'ring': 1705, 'rings': 1706, 'rip': 1707, 'risk': 1708, 'rita': 1709, 'river': 1710, 'road': 1711, 'rob': 1712, 'robo': 1713, 'rock': 1714, 'rockin': 1715, 'rocking': 1716, 'rocks': 1717, 'rodeo': 1718, 'role': 1719, 'roll': 1720, 'rollie': 1721, 'rolling': 1722, 'rolls': 1723, 'roly': 1724, 'rompe': 1725, 'roof': 1726, 'rookie': 1727, 'room': 1728, 'ropa': 1729, 'rope': 1730, 'rose': 1731, 'ross': 1732, 'rossa': 1733, 'round': 1734, 'rove': 1735, 'row': 1736, 'rrr': 1737, 'rrrr': 1738, 'rubber': 1739, 'rubbers': 1740, 'rude': 1741, 'run': 1742, 'runnin': 1743, 'running': 1744, 'ruthless': 1745, 'sabroso': 1746, 'sacks': 1747, 'safe': 1748, 'said': 1749, 'saint': 1750, 'saks': 1751, 'sales': 1752, 'salgo': 1753, 'salty': 1754, 'saludes': 1755, 'same': 1756, 'san': 1757, 'sandwiches': 1758, 'sang': 1759, 'sano': 1760, 'saturday': 1761, 'sauce': 1762, 'saudi': 1763, 'savage': 1764, 'savior': 1765, 'saw': 1766, 'say': 1767, 'saying': 1768, 'sazon': 1769, 'scenarios': 1770, 'scene': 1771, 'school': 1772, 'scissor': 1773, 'scope': 1774, 'scott': 1775, 'screenshotted': 1776, 'screwed': 1777, 'script': 1778, 'scuffed': 1779, 'scuffle': 1780, 'se': 1781, 'season': 1782, \"season's\": 1783, 'seater': 1784, 'sec': 1785, 'seco': 1786, 'second': 1787, 'seduce': 1788, 'see': 1789, 'seen': 1790, 'seis': 1791, 'selena': 1792, 'self': 1793, 'sell': 1794, 'send': 1795, 'sendin': 1796, 'senora': 1797, 'sense': 1798, 'serena': 1799, 'serious': 1800, 'serve': 1801, 'set': 1802, 'seven': 1803, 'sew': 1804, 'sex': 1805, 'sexy': 1806, 'shade': 1807, 'shady': 1808, 'shake': 1809, 'shape': 1810, 'shawty': 1811, 'she': 1812, \"she's\": 1813, 'shift': 1814, 'shiftin': 1815, 'shine': 1816, 'shinin': 1817, 'shining': 1818, 'shit': 1819, 'shoes': 1820, 'shook': 1821, 'shoot': 1822, 'shootin': 1823, 'shopping': 1824, 'shorty': 1825, 'shots': 1826, 'should': 1827, 'shoulder': 1828, 'shoulders': 1829, \"shouldn't\": 1830, 'shout': 1831, 'show': 1832, 'showin': 1833, 'showing': 1834, 'shows': 1835, 'shut': 1836, 'si': 1837, 'sick': 1838, 'sided': 1839, 'siempre': 1840, 'sientas': 1841, 'sig': 1842, 'sight': 1843, 'signin': 1844, 'sin': 1845, 'since': 1846, 'singer': 1847, 'singles': 1848, 'sins': 1849, 'sip': 1850, 'sis': 1851, 'sit': 1852, 'six': 1853, 'ski': 1854, 'skirt': 1855, 'skrrr': 1856, 'skrrt': 1857, 'slaps': 1858, 'slaved': 1859, 'sleep': 1860, 'sleepin': 1861, 'sleeping': 1862, 'slice': 1863, 'slide': 1864, 'slim': 1865, 'slip': 1866, 'slippin': 1867, 'slow': 1868, 'slowly': 1869, 'slump': 1870, 'smack': 1871, 'small': 1872, 'smash': 1873, 'smell': 1874, 'smile': 1875, 'smilin': 1876, 'smoke': 1877, 'smoked': 1878, 'smooth': 1879, 'snack': 1880, 'snapped': 1881, 'sneak': 1882, 'sneakers': 1883, 'snorted': 1884, 'snuka': 1885, 'so': 1886, 'sober': 1887, 'socks': 1888, 'sodium': 1889, 'sofrito': 1890, 'soft': 1891, 'sola': 1892, 'soldier': 1893, 'somali': 1894, 'some': 1895, 'someone': 1896, 'something': 1897, 'sometimes': 1898, 'somos': 1899, 'son': 1900, 'sonando': 1901, 'soon': 1902, 'sorry': 1903, 'sound': 1904, 'sounds': 1905, 'soup': 1906, 'source': 1907, 'soy': 1908, 'space': 1909, 'speak': 1910, 'speaker': 1911, 'speakin': 1912, 'spears': 1913, 'special': 1914, 'specially': 1915, 'spend': 1916, 'spent': 1917, 'sperm': 1918, 'spice': 1919, 'spicy': 1920, 'spillin': 1921, 'spit': 1922, 'spite': 1923, 'spittin': 1924, 'splash': 1925, 'spoil': 1926, 'spoke': 1927, 'sport': 1928, 'sports': 1929, 'spot': 1930, 'spread': 1931, 'sprinter': 1932, 'stab': 1933, 'stabbing': 1934, 'stack': 1935, 'stairs': 1936, 'stall': 1937, 'stamp': 1938, 'stand': 1939, 'standing': 1940, 'stands': 1941, 'stank': 1942, 'stare': 1943, 'start': 1944, 'started': 1945, 'stats': 1946, 'stay': 1947, 'stayed': 1948, 'steak': 1949, 'steal': 1950, 'step': 1951, 'steph': 1952, 'steppin': 1953, 'stereo': 1954, 'sticky': 1955, 'still': 1956, 'stilts': 1957, 'stink': 1958, 'stirring': 1959, 'stock': 1960, 'stomach': 1961, 'stop': 1962, 'stopping': 1963, 'stops': 1964, 'store': 1965, 'story': 1966, 'stove': 1967, 'straight': 1968, 'strap': 1969, 'strapped': 1970, 'straw': 1971, 'street': 1972, 'streets': 1973, 'stressed': 1974, 'strip': 1975, 'stripper': 1976, 'strippin': 1977, 'stroke': 1978, 'stu': 1979, 'study': 1980, 'stunt': 1981, 'stuntin': 1982, 'stunting': 1983, 'stunts': 1984, 'stupid': 1985, 'stutter': 1986, 'style': 1987, 'su': 1988, 'subs': 1989, 'suck': 1990, 'suckin': 1991, 'sucking': 1992, 'sudando': 1993, \"sue's\": 1994, 'suelta': 1995, 'suffocate': 1996, 'sufre': 1997, 'suicide': 1998, 'summer': 1999, 'sun': 2000, 'support': 2001, 'sure': 2002, 'surprise': 2003, 'swag': 2004, 'swap': 2005, 'swear': 2006, 'sweat': 2007, 'sweet': 2008, 'swim': 2009, 'swipe': 2010, 'switch': 2011, 'switchin': 2012, 't': 2013, 'ta': 2014, 'taba': 2015, 'tag': 2016, 'tailored': 2017, 'take': 2018, 'taken': 2019, 'takeoff': 2020, 'takin': 2021, 'tale': 2022, 'talk': 2023, 'talkin': 2024, 'talking': 2025, 'tall': 2026, 'tamale': 2027, 'tambien': 2028, 'tamed': 2029, 'tan': 2030, 'tank': 2031, 'tantas': 2032, 'target': 2033, 'tastes': 2034, 'tay': 2035, 'te': 2036, 'teach': 2037, 'tear': 2038, 'tears': 2039, 'tease': 2040, 'teaspoon': 2041, 'teeth': 2042, 'teigen': 2043, 'tell': 2044, 'tellin': 2045, 'telly': 2046, 'ten': 2047, 'tengo': 2048, 'tenis': 2049, 'testarossa': 2050, 'text': 2051, 'texts': 2052, 'than': 2053, 'thank': 2054, 'that': 2055, \"that'll\": 2056, \"that's\": 2057, 'the': 2058, 'their': 2059, 'them': 2060, 'then': 2061, 'there': 2062, \"there's\": 2063, 'these': 2064, 'they': 2065, \"they're\": 2066, 'thick': 2067, 'thighs': 2068, 'thing': 2069, 'things': 2070, 'think': 2071, 'thinkin': 2072, 'thinking': 2073, 'this': 2074, 'those': 2075, 'thot': 2076, 'thottie': 2077, 'though': 2078, 'thought': 2079, 'threat': 2080, 'three': 2081, 'threesome': 2082, 'thriller': 2083, 'through': 2084, 'throw': 2085, 'throwin': 2086, 'throwing': 2087, 'thumb': 2088, 'ti': 2089, 'tick': 2090, 'tie': 2091, 'tight': 2092, 'til': 2093, 'time': 2094, 'times': 2095, 'timid': 2096, 'tinder': 2097, 'tinted': 2098, 'tip': 2099, 'tippin': 2100, 'tired': 2101, 'titties': 2102, 'titty': 2103, 'tlc': 2104, 'to': 2105, \"to'a\": 2106, \"to'as\": 2107, 'toca': 2108, 'todas': 2109, 'todo': 2110, 'together': 2111, 'told': 2112, 'tolerance': 2113, 'tom': 2114, 'tommy': 2115, 'tone': 2116, 'tongue': 2117, 'tongues': 2118, 'tonight': 2119, 'too': 2120, 'took': 2121, 'top': 2122, 'tops': 2123, 'tortoise': 2124, 'tote': 2125, 'touch': 2126, 'tough': 2127, 'tour': 2128, 'towel': 2129, 'town': 2130, 'toy': 2131, 'train': 2132, 'trainer': 2133, 'trap': 2134, 'trappin': 2135, 'traps': 2136, 'trash': 2137, 'trato': 2138, 'treat': 2139, 'treatin': 2140, 'trickin': 2141, 'tripled': 2142, 'trippin': 2143, 'tropicana': 2144, 'trouble': 2145, 'truck': 2146, 'trunk': 2147, 'trust': 2148, 'try': 2149, 'trying': 2150, 'tryna': 2151, 'tu': 2152, 'tumbar': 2153, 'tuna': 2154, 'turn': 2155, 'turned': 2156, 'turns': 2157, 'tuya': 2158, 'tv': 2159, 'twerk': 2160, 'twerkin': 2161, 'twins': 2162, 'twitter': 2163, 'two': 2164, 'type': 2165, 'uh': 2166, 'umm': 2167, 'un': 2168, 'una': 2169, 'unattractive': 2170, 'understand': 2171, 'unemployed': 2172, 'unimportant': 2173, 'unlike': 2174, 'until': 2175, 'up': 2176, 'upset': 2177, 'us': 2178, 'used': 2179, 'uzi': 2180, 'vag': 2181, 'valentin': 2182, 'vamanos': 2183, 'vamo': 2184, 'vamos': 2185, 'ven': 2186, 'venchy': 2187, 'venezolanas': 2188, 'verdad': 2189, 'versace': 2190, 'verse': 2191, 'ves': 2192, 'vest': 2193, 'viajes': 2194, 'viceland': 2195, 'viera': 2196, 'views': 2197, 'vio': 2198, 'violence': 2199, 'violent': 2200, 'vip': 2201, 'vision': 2202, 'visto': 2203, 'viva': 2204, 'vive': 2205, \"vo'a\": 2206, 'voila': 2207, 'vroom': 2208, 'vvs': 2209, 'waist': 2210, 'wait': 2211, 'waited': 2212, 'waitress': 2213, 'wakanda': 2214, 'wake': 2215, 'walk': 2216, 'walked': 2217, 'walkin': 2218, 'wallet': 2219, 'wanna': 2220, 'wannabe': 2221, 'want': 2222, 'wanted': 2223, 'warnin': 2224, 'was': 2225, \"wasn't\": 2226, 'waste': 2227, 'watch': 2228, 'watches': 2229, 'watching': 2230, 'water': 2231, 'wave': 2232, 'way': 2233, 'we': 2234, \"we'll\": 2235, \"we've\": 2236, 'weak': 2237, 'wear': 2238, 'wearin': 2239, 'weave': 2240, 'weed': 2241, 'week': 2242, 'weekend': 2243, 'well': 2244, 'went': 2245, 'wept': 2246, 'were': 2247, 'wet': 2248, 'what': 2249, \"what'd\": 2250, \"what's\": 2251, 'whatever': 2252, 'whats': 2253, 'wheel': 2254, 'wheels': 2255, 'when': 2256, 'whenever': 2257, 'where': 2258, \"where's\": 2259, 'whew': 2260, 'while': 2261, 'whip': 2262, 'whispered': 2263, 'white': 2264, 'who': 2265, \"who's\": 2266, 'whoever': 2267, 'whole': 2268, 'whoo': 2269, 'whose': 2270, 'why': 2271, 'wic': 2272, 'wide': 2273, 'widow': 2274, 'wife': 2275, 'wild': 2276, 'will': 2277, 'willie': 2278, 'win': 2279, 'wine': 2280, 'winning': 2281, 'wipe': 2282, 'wish': 2283, 'wishlist': 2284, 'with': 2285, 'without': 2286, 'woah': 2287, 'woke': 2288, 'women': 2289, 'won': 2290, \"won't\": 2291, 'wonder': 2292, 'woo': 2293, 'wood': 2294, 'word': 2295, 'work': 2296, 'worker': 2297, 'workin': 2298, 'working': 2299, 'world': 2300, 'worse': 2301, 'worth': 2302, 'would': 2303, \"would've\": 2304, \"wouldn't\": 2305, 'wow': 2306, 'wraith': 2307, 'wrap': 2308, 'wrist': 2309, 'write': 2310, 'wrong': 2311, 'wuh': 2312, 'xans': 2313, 'y': 2314, \"y'all\": 2315, 'ya': 2316, 'yacht': 2317, 'yeah': 2318, 'year': 2319, 'yee': 2320, 'yeh': 2321, 'yelba': 2322, 'yes': 2323, 'yesca': 2324, 'yet': 2325, 'yo': 2326, 'yolk': 2327, 'yonce': 2328, 'york': 2329, 'you': 2330, \"you'd\": 2331, \"you'da\": 2332, \"you're\": 2333, \"you's\": 2334, \"you've\": 2335, 'young': 2336, 'your': 2337, 'yours': 2338, 'yuh': 2339, 'yves': 2340}\n",
      "vocabulary size: 2341\n"
     ]
    }
   ],
   "source": [
    "vocab = set(all_lyric_lines)\n",
    "vocab = sorted(vocab)\n",
    "\n",
    "word_to_index = {w: i for i, w in enumerate(vocab)}\n",
    "index_to_word = {i: w for w, i in word_to_index.items()}\n",
    "word_indices = [word_to_index[word] for word in vocab]\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "print(word_to_index)\n",
    "print('vocabulary size: {}'.format(vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokenized_lines(lines, seq_len):\n",
    "    tokenized = np.zeros((len(lines), seq_len))\n",
    "    \n",
    "    for r, line in enumerate(lines):\n",
    "        for c, word in enumerate(line):\n",
    "            tokenized[r, c] = word_to_index[word]\n",
    "\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_seq = get_tokenized_lines(sequences, SEQ_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19353,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_seq[:, -1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "X, y = tokenized_seq[:, :-1], tokenized_seq[:, -1]\n",
    "y = to_categorical(y, num_classes=vocab_size)\n",
    "seq_length = len(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_shape (19353, 50)\n",
      "y_shape (19353, 2341)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_shape\", X.shape)\n",
    "print(\"y_shape\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 50, 50)            117050    \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 50, 100)           60400     \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2341)              236441    \n",
      "=================================================================\n",
      "Total params: 504,391\n",
      "Trainable params: 504,391\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "152/152 [==============================] - 19s 123ms/step - loss: 6.4580 - accuracy: 0.0435\n",
      "Epoch 2/200\n",
      "152/152 [==============================] - 18s 119ms/step - loss: 6.0990 - accuracy: 0.0484\n",
      "Epoch 3/200\n",
      "152/152 [==============================] - 16s 107ms/step - loss: 5.9223 - accuracy: 0.0489\n",
      "Epoch 4/200\n",
      "152/152 [==============================] - 17s 109ms/step - loss: 5.7389 - accuracy: 0.0541\n",
      "Epoch 5/200\n",
      "152/152 [==============================] - 16s 108ms/step - loss: 5.5518 - accuracy: 0.0609\n",
      "Epoch 6/200\n",
      "152/152 [==============================] - 17s 112ms/step - loss: 5.3796 - accuracy: 0.0654\n",
      "Epoch 7/200\n",
      "152/152 [==============================] - 19s 126ms/step - loss: 5.2234 - accuracy: 0.0728\n",
      "Epoch 8/200\n",
      "152/152 [==============================] - 23s 150ms/step - loss: 5.0616 - accuracy: 0.0832\n",
      "Epoch 9/200\n",
      "152/152 [==============================] - 19s 122ms/step - loss: 4.9097 - accuracy: 0.0951\n",
      "Epoch 10/200\n",
      "152/152 [==============================] - 22s 142ms/step - loss: 4.7555 - accuracy: 0.1069\n",
      "Epoch 11/200\n",
      "152/152 [==============================] - 22s 147ms/step - loss: 4.6071 - accuracy: 0.1173\n",
      "Epoch 12/200\n",
      "152/152 [==============================] - 20s 131ms/step - loss: 4.5489 - accuracy: 0.1249\n",
      "Epoch 13/200\n",
      "152/152 [==============================] - 23s 148ms/step - loss: 4.3710 - accuracy: 0.1407\n",
      "Epoch 14/200\n",
      "152/152 [==============================] - 39s 259ms/step - loss: 4.2430 - accuracy: 0.1582\n",
      "Epoch 15/200\n",
      "152/152 [==============================] - 31s 205ms/step - loss: 4.1229 - accuracy: 0.1723\n",
      "Epoch 16/200\n",
      "152/152 [==============================] - 21s 140ms/step - loss: 3.9985 - accuracy: 0.1926\n",
      "Epoch 17/200\n",
      "152/152 [==============================] - 23s 154ms/step - loss: 3.8867 - accuracy: 0.2061\n",
      "Epoch 18/200\n",
      "152/152 [==============================] - 23s 150ms/step - loss: 3.7811 - accuracy: 0.2231\n",
      "Epoch 19/200\n",
      "152/152 [==============================] - 22s 144ms/step - loss: 3.6584 - accuracy: 0.2439\n",
      "Epoch 20/200\n",
      "152/152 [==============================] - 20s 132ms/step - loss: 3.5526 - accuracy: 0.2567\n",
      "Epoch 21/200\n",
      "152/152 [==============================] - 21s 141ms/step - loss: 3.4523 - accuracy: 0.2735\n",
      "Epoch 22/200\n",
      "152/152 [==============================] - 20s 134ms/step - loss: 3.3571 - accuracy: 0.2878\n",
      "Epoch 23/200\n",
      "152/152 [==============================] - 22s 144ms/step - loss: 3.2616 - accuracy: 0.3060\n",
      "Epoch 24/200\n",
      "152/152 [==============================] - 23s 150ms/step - loss: 3.1724 - accuracy: 0.3161\n",
      "Epoch 25/200\n",
      "152/152 [==============================] - 18s 117ms/step - loss: 3.0933 - accuracy: 0.3315\n",
      "Epoch 26/200\n",
      "152/152 [==============================] - 18s 116ms/step - loss: 3.0057 - accuracy: 0.3475\n",
      "Epoch 27/200\n",
      "152/152 [==============================] - 19s 125ms/step - loss: 2.9261 - accuracy: 0.3576\n",
      "Epoch 28/200\n",
      "152/152 [==============================] - 26s 174ms/step - loss: 2.8533 - accuracy: 0.3746\n",
      "Epoch 29/200\n",
      "152/152 [==============================] - 21s 139ms/step - loss: 2.7828 - accuracy: 0.3857\n",
      "Epoch 30/200\n",
      "152/152 [==============================] - 21s 136ms/step - loss: 2.7153 - accuracy: 0.4000\n",
      "Epoch 31/200\n",
      "152/152 [==============================] - 27s 175ms/step - loss: 2.6579 - accuracy: 0.4094\n",
      "Epoch 32/200\n",
      "152/152 [==============================] - 20s 129ms/step - loss: 2.5899 - accuracy: 0.4211\n",
      "Epoch 33/200\n",
      "152/152 [==============================] - 24s 155ms/step - loss: 2.5253 - accuracy: 0.4358\n",
      "Epoch 34/200\n",
      "152/152 [==============================] - 16s 108ms/step - loss: 2.4668 - accuracy: 0.4482\n",
      "Epoch 35/200\n",
      "152/152 [==============================] - 22s 144ms/step - loss: 2.4059 - accuracy: 0.4611\n",
      "Epoch 36/200\n",
      "152/152 [==============================] - 23s 150ms/step - loss: 2.3537 - accuracy: 0.4716\n",
      "Epoch 37/200\n",
      "152/152 [==============================] - 20s 135ms/step - loss: 2.3113 - accuracy: 0.4788\n",
      "Epoch 38/200\n",
      "152/152 [==============================] - 25s 163ms/step - loss: 2.2441 - accuracy: 0.4960\n",
      "Epoch 39/200\n",
      "152/152 [==============================] - 23s 150ms/step - loss: 2.1867 - accuracy: 0.5066\n",
      "Epoch 40/200\n",
      "152/152 [==============================] - 20s 133ms/step - loss: 2.1424 - accuracy: 0.5157\n",
      "Epoch 41/200\n",
      "152/152 [==============================] - 28s 187ms/step - loss: 2.0938 - accuracy: 0.5234\n",
      "Epoch 42/200\n",
      "152/152 [==============================] - 23s 149ms/step - loss: 2.0529 - accuracy: 0.5322\n",
      "Epoch 43/200\n",
      "152/152 [==============================] - 21s 140ms/step - loss: 2.0075 - accuracy: 0.5439\n",
      "Epoch 44/200\n",
      "152/152 [==============================] - 21s 136ms/step - loss: 1.9688 - accuracy: 0.5512\n",
      "Epoch 45/200\n",
      "152/152 [==============================] - 19s 127ms/step - loss: 1.9168 - accuracy: 0.5603\n",
      "Epoch 46/200\n",
      "152/152 [==============================] - 16s 108ms/step - loss: 1.8798 - accuracy: 0.5693\n",
      "Epoch 47/200\n",
      "152/152 [==============================] - 17s 110ms/step - loss: 1.8402 - accuracy: 0.5777\n",
      "Epoch 48/200\n",
      "152/152 [==============================] - 20s 129ms/step - loss: 1.8026 - accuracy: 0.5869\n",
      "Epoch 49/200\n",
      "152/152 [==============================] - 18s 115ms/step - loss: 1.7632 - accuracy: 0.5937\n",
      "Epoch 50/200\n",
      "152/152 [==============================] - 17s 112ms/step - loss: 1.7291 - accuracy: 0.6008\n",
      "Epoch 51/200\n",
      "152/152 [==============================] - 18s 118ms/step - loss: 1.6885 - accuracy: 0.6085\n",
      "Epoch 52/200\n",
      "152/152 [==============================] - 19s 128ms/step - loss: 1.6536 - accuracy: 0.6165\n",
      "Epoch 53/200\n",
      "152/152 [==============================] - 19s 128ms/step - loss: 1.6307 - accuracy: 0.6185\n",
      "Epoch 54/200\n",
      "152/152 [==============================] - 23s 151ms/step - loss: 1.5904 - accuracy: 0.6281\n",
      "Epoch 55/200\n",
      "152/152 [==============================] - 19s 127ms/step - loss: 1.5659 - accuracy: 0.6343\n",
      "Epoch 56/200\n",
      "152/152 [==============================] - 21s 140ms/step - loss: 1.5301 - accuracy: 0.6412\n",
      "Epoch 57/200\n",
      "152/152 [==============================] - 22s 146ms/step - loss: 1.5200 - accuracy: 0.6451\n",
      "Epoch 58/200\n",
      "152/152 [==============================] - 17s 114ms/step - loss: 1.4973 - accuracy: 0.6486\n",
      "Epoch 59/200\n",
      "152/152 [==============================] - 25s 165ms/step - loss: 1.4572 - accuracy: 0.6569\n",
      "Epoch 60/200\n",
      "152/152 [==============================] - 20s 133ms/step - loss: 1.4296 - accuracy: 0.6631\n",
      "Epoch 61/200\n",
      "152/152 [==============================] - 24s 159ms/step - loss: 1.4011 - accuracy: 0.6674\n",
      "Epoch 62/200\n",
      "152/152 [==============================] - 20s 134ms/step - loss: 1.3777 - accuracy: 0.6760\n",
      "Epoch 63/200\n",
      "152/152 [==============================] - 24s 156ms/step - loss: 1.3460 - accuracy: 0.6791\n",
      "Epoch 64/200\n",
      "152/152 [==============================] - 23s 150ms/step - loss: 1.3222 - accuracy: 0.6857\n",
      "Epoch 65/200\n",
      "152/152 [==============================] - 20s 132ms/step - loss: 1.3015 - accuracy: 0.6904\n",
      "Epoch 66/200\n",
      "152/152 [==============================] - 22s 142ms/step - loss: 1.2678 - accuracy: 0.6987\n",
      "Epoch 67/200\n",
      "152/152 [==============================] - 20s 131ms/step - loss: 1.2455 - accuracy: 0.7045\n",
      "Epoch 68/200\n",
      "152/152 [==============================] - 19s 125ms/step - loss: 1.2223 - accuracy: 0.7072\n",
      "Epoch 69/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 19s 127ms/step - loss: 1.2100 - accuracy: 0.7116\n",
      "Epoch 70/200\n",
      "152/152 [==============================] - 22s 145ms/step - loss: 1.1828 - accuracy: 0.7170\n",
      "Epoch 71/200\n",
      "152/152 [==============================] - 18s 120ms/step - loss: 1.1711 - accuracy: 0.7206\n",
      "Epoch 72/200\n",
      "152/152 [==============================] - 17s 113ms/step - loss: 1.1463 - accuracy: 0.7225\n",
      "Epoch 73/200\n",
      "152/152 [==============================] - 23s 151ms/step - loss: 1.1244 - accuracy: 0.7261\n",
      "Epoch 74/200\n",
      "152/152 [==============================] - 23s 152ms/step - loss: 1.0996 - accuracy: 0.7352\n",
      "Epoch 75/200\n",
      "152/152 [==============================] - 28s 184ms/step - loss: 1.0743 - accuracy: 0.7429\n",
      "Epoch 76/200\n",
      "152/152 [==============================] - 19s 122ms/step - loss: 1.0603 - accuracy: 0.7443\n",
      "Epoch 77/200\n",
      "152/152 [==============================] - 16s 105ms/step - loss: 1.0320 - accuracy: 0.7484\n",
      "Epoch 78/200\n",
      "152/152 [==============================] - 16s 106ms/step - loss: 1.0130 - accuracy: 0.7556\n",
      "Epoch 79/200\n",
      "152/152 [==============================] - 16s 105ms/step - loss: 1.0030 - accuracy: 0.7571\n",
      "Epoch 80/200\n",
      "152/152 [==============================] - 16s 105ms/step - loss: 0.9823 - accuracy: 0.7625\n",
      "Epoch 81/200\n",
      "152/152 [==============================] - 16s 105ms/step - loss: 0.9557 - accuracy: 0.7667\n",
      "Epoch 82/200\n",
      "152/152 [==============================] - 16s 106ms/step - loss: 0.9432 - accuracy: 0.7704\n",
      "Epoch 83/200\n",
      "152/152 [==============================] - 16s 105ms/step - loss: 0.9293 - accuracy: 0.7729\n",
      "Epoch 84/200\n",
      "152/152 [==============================] - 16s 105ms/step - loss: 0.9062 - accuracy: 0.7791\n",
      "Epoch 85/200\n",
      "152/152 [==============================] - 16s 106ms/step - loss: 0.8846 - accuracy: 0.7861\n",
      "Epoch 86/200\n",
      "152/152 [==============================] - 16s 106ms/step - loss: 0.8686 - accuracy: 0.7876\n",
      "Epoch 87/200\n",
      "152/152 [==============================] - 16s 106ms/step - loss: 0.8518 - accuracy: 0.7897\n",
      "Epoch 88/200\n",
      "152/152 [==============================] - 16s 105ms/step - loss: 0.8398 - accuracy: 0.7966\n",
      "Epoch 89/200\n",
      "152/152 [==============================] - 16s 104ms/step - loss: 0.8220 - accuracy: 0.7986\n",
      "Epoch 90/200\n",
      "152/152 [==============================] - 16s 106ms/step - loss: 0.8117 - accuracy: 0.8000\n",
      "Epoch 91/200\n",
      "152/152 [==============================] - 16s 105ms/step - loss: 0.7937 - accuracy: 0.8070\n",
      "Epoch 92/200\n",
      "152/152 [==============================] - 16s 105ms/step - loss: 0.7939 - accuracy: 0.8049\n",
      "Epoch 93/200\n",
      "152/152 [==============================] - 16s 106ms/step - loss: 0.7626 - accuracy: 0.8115\n",
      "Epoch 94/200\n",
      "152/152 [==============================] - 16s 103ms/step - loss: 0.7441 - accuracy: 0.8173\n",
      "Epoch 95/200\n",
      "152/152 [==============================] - 17s 111ms/step - loss: 0.7200 - accuracy: 0.8257\n",
      "Epoch 96/200\n",
      "152/152 [==============================] - 15s 99ms/step - loss: 0.7135 - accuracy: 0.8266\n",
      "Epoch 97/200\n",
      "152/152 [==============================] - 14s 95ms/step - loss: 0.7015 - accuracy: 0.8279\n",
      "Epoch 98/200\n",
      "152/152 [==============================] - 15s 95ms/step - loss: 0.6890 - accuracy: 0.8309\n",
      "Epoch 99/200\n",
      "152/152 [==============================] - 14s 94ms/step - loss: 0.6794 - accuracy: 0.8321\n",
      "Epoch 100/200\n",
      "152/152 [==============================] - 14s 93ms/step - loss: 0.6537 - accuracy: 0.8385\n",
      "Epoch 101/200\n",
      "152/152 [==============================] - 14s 93ms/step - loss: 0.6554 - accuracy: 0.8385\n",
      "Epoch 102/200\n",
      "152/152 [==============================] - 15s 100ms/step - loss: 0.6284 - accuracy: 0.8480\n",
      "Epoch 103/200\n",
      "152/152 [==============================] - 16s 108ms/step - loss: 0.6150 - accuracy: 0.8503\n",
      "Epoch 104/200\n",
      "152/152 [==============================] - 18s 119ms/step - loss: 0.5988 - accuracy: 0.8520\n",
      "Epoch 105/200\n",
      "152/152 [==============================] - 17s 113ms/step - loss: 0.5923 - accuracy: 0.8550\n",
      "Epoch 106/200\n",
      "152/152 [==============================] - 16s 103ms/step - loss: 0.5787 - accuracy: 0.8574\n",
      "Epoch 107/200\n",
      "152/152 [==============================] - 18s 118ms/step - loss: 0.5757 - accuracy: 0.8587\n",
      "Epoch 108/200\n",
      "152/152 [==============================] - 19s 122ms/step - loss: 0.5625 - accuracy: 0.8628\n",
      "Epoch 109/200\n",
      "152/152 [==============================] - 18s 120ms/step - loss: 0.5376 - accuracy: 0.8693\n",
      "Epoch 110/200\n",
      "152/152 [==============================] - 16s 107ms/step - loss: 0.5325 - accuracy: 0.8707\n",
      "Epoch 111/200\n",
      "152/152 [==============================] - 17s 111ms/step - loss: 0.5189 - accuracy: 0.8736\n",
      "Epoch 112/200\n",
      "152/152 [==============================] - 18s 115ms/step - loss: 0.5068 - accuracy: 0.8763\n",
      "Epoch 113/200\n",
      "152/152 [==============================] - 17s 114ms/step - loss: 0.4879 - accuracy: 0.8839\n",
      "Epoch 114/200\n",
      "152/152 [==============================] - 17s 115ms/step - loss: 0.4860 - accuracy: 0.8829\n",
      "Epoch 115/200\n",
      "152/152 [==============================] - 17s 111ms/step - loss: 0.4776 - accuracy: 0.8860\n",
      "Epoch 116/200\n",
      "152/152 [==============================] - 18s 118ms/step - loss: 0.4640 - accuracy: 0.8883\n",
      "Epoch 117/200\n",
      "152/152 [==============================] - 17s 110ms/step - loss: 0.4445 - accuracy: 0.8956\n",
      "Epoch 118/200\n",
      "152/152 [==============================] - 17s 110ms/step - loss: 0.4438 - accuracy: 0.8927\n",
      "Epoch 119/200\n",
      "152/152 [==============================] - 17s 114ms/step - loss: 0.4415 - accuracy: 0.8931\n",
      "Epoch 120/200\n",
      "152/152 [==============================] - 18s 121ms/step - loss: 0.4312 - accuracy: 0.8966\n",
      "Epoch 121/200\n",
      "152/152 [==============================] - 17s 110ms/step - loss: 0.4237 - accuracy: 0.8986\n",
      "Epoch 122/200\n",
      "152/152 [==============================] - 17s 110ms/step - loss: 0.4072 - accuracy: 0.9013\n",
      "Epoch 123/200\n",
      "152/152 [==============================] - 19s 128ms/step - loss: 0.4082 - accuracy: 0.9020\n",
      "Epoch 124/200\n",
      "152/152 [==============================] - 17s 113ms/step - loss: 0.3809 - accuracy: 0.9106\n",
      "Epoch 125/200\n",
      "152/152 [==============================] - 17s 114ms/step - loss: 0.3669 - accuracy: 0.9129\n",
      "Epoch 126/200\n",
      "152/152 [==============================] - 17s 111ms/step - loss: 0.3655 - accuracy: 0.9124\n",
      "Epoch 127/200\n",
      "152/152 [==============================] - 17s 113ms/step - loss: 0.3497 - accuracy: 0.9177\n",
      "Epoch 128/200\n",
      "152/152 [==============================] - 18s 117ms/step - loss: 0.3505 - accuracy: 0.9177\n",
      "Epoch 129/200\n",
      "152/152 [==============================] - 17s 111ms/step - loss: 0.3474 - accuracy: 0.9169\n",
      "Epoch 130/200\n",
      "152/152 [==============================] - 17s 110ms/step - loss: 0.3447 - accuracy: 0.9199\n",
      "Epoch 131/200\n",
      "152/152 [==============================] - 20s 131ms/step - loss: 0.3229 - accuracy: 0.9245\n",
      "Epoch 132/200\n",
      "152/152 [==============================] - 18s 121ms/step - loss: 0.3250 - accuracy: 0.9254\n",
      "Epoch 133/200\n",
      "152/152 [==============================] - 18s 119ms/step - loss: 0.3042 - accuracy: 0.9317\n",
      "Epoch 134/200\n",
      "152/152 [==============================] - 18s 121ms/step - loss: 0.3001 - accuracy: 0.9318\n",
      "Epoch 135/200\n",
      "152/152 [==============================] - 18s 115ms/step - loss: 0.2824 - accuracy: 0.9368\n",
      "Epoch 136/200\n",
      "152/152 [==============================] - 18s 116ms/step - loss: 0.2687 - accuracy: 0.9414\n",
      "Epoch 137/200\n",
      "152/152 [==============================] - 18s 119ms/step - loss: 0.2638 - accuracy: 0.9418\n",
      "Epoch 138/200\n",
      "152/152 [==============================] - 20s 134ms/step - loss: 0.2783 - accuracy: 0.9368\n",
      "Epoch 139/200\n",
      "152/152 [==============================] - 20s 129ms/step - loss: 0.2733 - accuracy: 0.9355\n",
      "Epoch 140/200\n",
      "152/152 [==============================] - 18s 117ms/step - loss: 0.2515 - accuracy: 0.9447\n",
      "Epoch 141/200\n",
      "152/152 [==============================] - 19s 123ms/step - loss: 0.2429 - accuracy: 0.9470\n",
      "Epoch 142/200\n",
      "152/152 [==============================] - 17s 115ms/step - loss: 0.2323 - accuracy: 0.9511\n",
      "Epoch 143/200\n",
      "152/152 [==============================] - 21s 137ms/step - loss: 0.2306 - accuracy: 0.9504\n",
      "Epoch 144/200\n",
      "152/152 [==============================] - 18s 121ms/step - loss: 0.2230 - accuracy: 0.9517\n",
      "Epoch 145/200\n",
      "152/152 [==============================] - 20s 133ms/step - loss: 0.2192 - accuracy: 0.9530\n",
      "Epoch 146/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 19s 124ms/step - loss: 0.2236 - accuracy: 0.9508\n",
      "Epoch 147/200\n",
      "152/152 [==============================] - 20s 132ms/step - loss: 0.2211 - accuracy: 0.9495\n",
      "Epoch 148/200\n",
      "152/152 [==============================] - 20s 131ms/step - loss: 0.2464 - accuracy: 0.9415\n",
      "Epoch 149/200\n",
      "152/152 [==============================] - 23s 150ms/step - loss: 0.2448 - accuracy: 0.9440\n",
      "Epoch 150/200\n",
      "152/152 [==============================] - 18s 116ms/step - loss: 0.2040 - accuracy: 0.9561\n",
      "Epoch 151/200\n",
      "152/152 [==============================] - 19s 123ms/step - loss: 0.1863 - accuracy: 0.9606\n",
      "Epoch 152/200\n",
      "152/152 [==============================] - 18s 119ms/step - loss: 0.1741 - accuracy: 0.9636\n",
      "Epoch 153/200\n",
      "152/152 [==============================] - 24s 157ms/step - loss: 0.1608 - accuracy: 0.9685\n",
      "Epoch 154/200\n",
      "152/152 [==============================] - 23s 151ms/step - loss: 0.1754 - accuracy: 0.9638\n",
      "Epoch 155/200\n",
      "152/152 [==============================] - 23s 153ms/step - loss: 0.1758 - accuracy: 0.9629\n",
      "Epoch 156/200\n",
      "152/152 [==============================] - 24s 161ms/step - loss: 0.1584 - accuracy: 0.9683\n",
      "Epoch 157/200\n",
      "152/152 [==============================] - 20s 130ms/step - loss: 0.1629 - accuracy: 0.9667\n",
      "Epoch 158/200\n",
      "152/152 [==============================] - 22s 143ms/step - loss: 0.1698 - accuracy: 0.9643\n",
      "Epoch 159/200\n",
      "152/152 [==============================] - 24s 158ms/step - loss: 0.2065 - accuracy: 0.9502\n",
      "Epoch 160/200\n",
      "152/152 [==============================] - 23s 153ms/step - loss: 0.1783 - accuracy: 0.9612\n",
      "Epoch 161/200\n",
      "152/152 [==============================] - 26s 169ms/step - loss: 0.1491 - accuracy: 0.9705\n",
      "Epoch 162/200\n",
      "152/152 [==============================] - 21s 141ms/step - loss: 0.1519 - accuracy: 0.9688\n",
      "Epoch 163/200\n",
      "152/152 [==============================] - 20s 131ms/step - loss: 0.1200 - accuracy: 0.9779\n",
      "Epoch 164/200\n",
      "152/152 [==============================] - 21s 137ms/step - loss: 0.1105 - accuracy: 0.9806\n",
      "Epoch 165/200\n",
      "152/152 [==============================] - 23s 153ms/step - loss: 0.1025 - accuracy: 0.9832\n",
      "Epoch 166/200\n",
      "152/152 [==============================] - 26s 170ms/step - loss: 0.1006 - accuracy: 0.9837\n",
      "Epoch 167/200\n",
      "152/152 [==============================] - 22s 147ms/step - loss: 0.1029 - accuracy: 0.9824\n",
      "Epoch 168/200\n",
      "152/152 [==============================] - 18s 115ms/step - loss: 0.1077 - accuracy: 0.9820\n",
      "Epoch 169/200\n",
      "152/152 [==============================] - 19s 127ms/step - loss: 0.1154 - accuracy: 0.9778\n",
      "Epoch 170/200\n",
      "152/152 [==============================] - 19s 128ms/step - loss: 0.1418 - accuracy: 0.9684\n",
      "Epoch 171/200\n",
      "152/152 [==============================] - 18s 118ms/step - loss: 0.1894 - accuracy: 0.9522\n",
      "Epoch 172/200\n",
      "152/152 [==============================] - 17s 109ms/step - loss: 0.1702 - accuracy: 0.9591\n",
      "Epoch 173/200\n",
      "152/152 [==============================] - 16s 106ms/step - loss: 0.1304 - accuracy: 0.9738\n",
      "Epoch 174/200\n",
      "152/152 [==============================] - 16s 107ms/step - loss: 0.1065 - accuracy: 0.9803\n",
      "Epoch 175/200\n",
      "152/152 [==============================] - 16s 108ms/step - loss: 0.0860 - accuracy: 0.9852\n",
      "Epoch 176/200\n",
      "152/152 [==============================] - 17s 109ms/step - loss: 0.0897 - accuracy: 0.9843\n",
      "Epoch 177/200\n",
      "152/152 [==============================] - 17s 113ms/step - loss: 0.1030 - accuracy: 0.9813\n",
      "Epoch 178/200\n",
      "152/152 [==============================] - 16s 107ms/step - loss: 0.1160 - accuracy: 0.9763\n",
      "Epoch 179/200\n",
      "145/152 [===========================>..] - ETA: 0s - loss: 0.1131 - accuracy: 0.9772"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 50, input_length=seq_length))\n",
    "model.add(LSTM(100, return_sequences=True))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "print(model.summary())\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(X, y, batch_size=128, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.save('word_model_cardi_b.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('word_model_eminem.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def texts_to_sequences(texts, word_to_index):\n",
    "    indices = np.zeros((1, len(texts)), dtype=int)\n",
    "    \n",
    "    for i, text in enumerate(texts):\n",
    "        if text not in word_to_index:\n",
    "            random = index_to_word[randint(0,vocab_size)]\n",
    "            indices[:, i] = word_to_index[random]\n",
    "        else:\n",
    "            indices[:, i] = word_to_index[text]\n",
    "        \n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_pad_sequences(seq, maxlen):\n",
    "    start = seq.shape[1] - maxlen\n",
    "    \n",
    "    return seq[:, start: start + maxlen]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_seq(model, word_to_index, seq_length, n_words):\n",
    "    generated = ''\n",
    "    usr_input = input(\"Write the beginning of your poem, the Drake machine will complete it. Your input is: \")\n",
    "    generated += usr_input \n",
    "    sys.stdout.write(\"\\n\\nHere is your poem: \\n\\n\") \n",
    "    \n",
    "    result = list()\n",
    "    in_text = [None] * 51\n",
    "    generated_list = generated.split()\n",
    "    \n",
    "    # if input is shorter than 51 words, fill the beginning with random words\n",
    "    if(len(generated_list) < 51):\n",
    "        end = len(generated_list)\n",
    "        for i in range (51 - end):\n",
    "            random = index_to_word[randint(0,vocab_size)]\n",
    "            in_text[i] = random\n",
    "            \n",
    "        index = 0\n",
    "        for i in range (51 - end, 51):\n",
    "            in_text[i] = generated_list[index]\n",
    "            index += 1\n",
    "\n",
    "    # if input is longer than 51 words, only use the last 51 words\n",
    "    if(len(generated_list) > 51):\n",
    "        end = len(generated_list)\n",
    "        in_text = generated_list[end-51:]\n",
    "\n",
    "    # generate words based on last 50 words\n",
    "    for _ in range(n_words):\n",
    "        encoded = texts_to_sequences(in_text[1:], word_to_index)\n",
    "        encoded = my_pad_sequences(encoded, maxlen=seq_length)\n",
    "        \n",
    "        yhat = model.predict_classes(encoded, verbose=0)\n",
    "        out_word = ''\n",
    "    \n",
    "        for word, index in word_to_index.items():\n",
    "            if index == yhat:\n",
    "                out_word = word\n",
    "                break\n",
    "        \n",
    "        in_text += ' ' + out_word\n",
    "        result.append(out_word)\n",
    "        \n",
    "    return ' '.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write the beginning of your poem, the Drake machine will complete it. Your input is: sdahfjashdfkjashd asdfh\n",
      "\n",
      "\n",
      "Here is your poem: \n",
      "\n",
      "['coke', 'cookin', \"problem's\", 'headache', 'fifth', 'ovulating', 'birth', 'dear', 'neither', 'grips', 'aight', 'pacquiao', 'truthful', 'mann', 'babe', 'misconducts', 'extraterrestrial', 'dodgers', 'smack', 'ruin', 'jade', 'chasing', 'cars', 'poppins', 'tear', 'legendary', 'sorry', 'plenty', 'lewinsky', 'outdo', 'raps', 'growing', 'wide', 'sister', \"you'ont\", 'opposites', 'winks', 'glide', 'huge', 'southpaw', 'grasp', 'symbolic', 'harris', 'come', 'helped', 'muster', 'sit', 'beer', 'sweden', 'sdahfjashdfkjashd', 'asdfh']\n",
      "envision fellatio fellow fellatio fellow denver clothes flippity christmas flippity cat triangle uh sa minimum fellatio fellow fellatio fellow fellatio groups resentment lazy hangs pectations jump pigeonholed ho's pinkett clothes pinkett clothes pinkett clothes pinkett lazy hangs bury idaho west pigeonholed fellatio fellow fellatio fellow fellatio fellow denver clothes pinkett\n"
     ]
    }
   ],
   "source": [
    "generated = generate_seq(model, word_to_index, seq_length, 50)\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
